{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"cell_id":"84ae7c990d6045948ee9821ebc116236","deepnote_cell_type":"markdown","tags":[]},"source":["# Úkol č. 1 - předzpracování dat a binární klasifikace\n","\n","  * **Deadline je do 3. 11. 2022, 23:59:59**, pokud odevzdáte úkol do 10. 11. 2022, 23:59:59, budete penalizování -4 body, pozdější odevzdání je bez bodu.\n","  * V rámci tohoto úkolu se musíte vypořádat s příznaky, které jsou různých typů.\n","  * Před tím, než na nich postavíte predikční model, je třeba je nějakým způsobem převést do číselné reprezentace.\n","    \n","> **Úkoly jsou zadány tak, aby Vám daly prostor pro invenci. Vymyslet _jak přesně_ budete úkol řešit, je důležitou součástí zadání a originalita či nápaditost bude také hodnocena!**\n","\n","## Zdroj dat\n","\n","Budeme se zabývat predikcí přežití pasažérů Titaniku.\n","K dispozici máte trénovací data v souboru **data.csv** a data na vyhodnocení v souboru **evaluation.csv**.\n","\n","#### Seznam příznaků:\n","* survived - zda přežil, 0 = Ne, 1 = Ano, **vysvětlovaná proměnná**, kterou chcete predikovat\n","* pclass - Třída lodního lístku, 1 = první, 2 = druhá, 3 = třetí\n","* name - jméno\n","* sex - pohlaví\n","* age - věk v letech\n","* sibsp\t- počet sourozenců / manželů, manželek na palubě\n","* parch - počet rodičů / dětí na palubě\n","* ticket - číslo lodního lístku\n","* fare - cena lodního lístku\n","* cabin\t- číslo kajuty\n","* embarked\t- místo nalodění, C = Cherbourg, Q = Queenstown, S = Southampton\n","* home.dest - Bydliště/Cíl\n","\n","## Pokyny k vypracování\n","\n","**Základní body zadání**, za jejichž (poctivé) vypracování získáte **12 bodů**:\n","  * Využívejte buňky typu `Markdown` k vysvětlování Vašeho postupu. Za nepřehlednost budeme strhávat body.\n","  * V notebooku načtěte data ze souboru **data.csv**. Vhodným způsobem si je rozdělte na podmnožiny potřebné k trénování a evaluaci modelu (optimálně tedy trénovací, validační a testovací).\n","  * Projděte si jednotlivé příznaky a transformujte je do vhodné podoby pro použití ve vybraném klasifikačním modelu.\n","  * Podle potřeby si můžete vytvářet nové příznaky (na základě existujících), například tedy můžete vytvořit příznak měřící délku jména. Některé příznaky můžete také úplně zahodit. Pro průzkum dat využívejte vizualizace.\n","  * Nějakým způsobem se vypořádejte s chybějícími hodnotami.\n","  * Následně si vyberte vhodný klasifikační model z přednášek. Najděte vhodné hyperparametry a určete jeho přesnost (accuracy) na trénovací množině. Také určete jeho přesnost na testovací množině.\n","  * Načtěte vyhodnocovací data ze souboru **evaluation.csv**. Napočítejte predikce pro tyto data (vysvětlovaná proměnná v nich již není). Vytvořte **results.csv** soubor, ve kterém tyto predikce uložíte do dvou sloupců: ID, predikce přežití. Tento soubor též odevzdejte (uložte do projektu vedle notebooku).\n","  * Ukázka prvních řádků souboru *results.csv*:\n","  \n","```\n","ID,survived\n","1000,0\n","1001,1\n","...\n","```\n","\n","**Další body zadání** za případné další body (můžete si vybrat, maximum bodů za úkol je každopádně 16 bodů):\n","  * (až +4 body) Aplikujte všechny klasifikační modely z přednášek a určete (na základě přesnosti na validační množině), který je nejlepší. Přesnost tohoto nejlepšího modelu odhadněte na testovací množině. K predikcím na vyhodnocovacích datech využijte tento model.\n","  * (až +4 body) Zaměřte se na optimální předzpracování dat. Zabývejte se tím, jak nejlépe zpracovat a reprezentovat kategoriální příznaky. Také zkuste data normalizovat. Zaměřte se na vliv těchto kroků na přesnost predikce výsledného modelu. K predikcím na vyhodnocovacích datech využijte ten přístup, který Vám vyjde jako nejlepší.\n","\n","## Poznámky k odevzdání\n","\n","  * Řiďte se pokyny ze stránky https://courses.fit.cvut.cz/BI-ML1/homeworks/index.html.\n","  * Vytvořte i csv soubor s predikcemi a uložte ho v rámci projektu (`results.csv`, vedle ipython notebooku).\n","  * Opravující Vám ve výjimečných případech může umožnit úkol dodělat či opravit a získat tak další body. První verze je ale stěžejní a má hlavní vliv na hodnocení."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Imports"]},{"cell_type":"code","execution_count":1,"metadata":{"cell_id":"5b2cb7803f6e4ba3b39e0ac1967ff50b","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":5,"execution_start":1665675807913,"source_hash":"3bd5fbb3","tags":[]},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","\n","from statistics import mean\n","from math import floor\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.model_selection import ParameterGrid\n","import sklearn.metrics as metrics\n","\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.preprocessing import MinMaxScaler\n","\n","import matplotlib.pyplot as plt\n","%matplotlib inline "]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Load data and check for Null values"]},{"cell_type":"code","execution_count":92,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","Index: 1000 entries, 53 to 652\n","Data columns (total 14 columns):\n"," #   Column     Non-Null Count  Dtype   \n","---  ------     --------------  -----   \n"," 0   ID         1000 non-null   int64   \n"," 1   survived   1000 non-null   int64   \n"," 2   pclass     1000 non-null   int64   \n"," 3   name       1000 non-null   object  \n"," 4   sex        1000 non-null   object  \n"," 5   age        1000 non-null   float64 \n"," 6   sibsp      1000 non-null   int64   \n"," 7   parch      1000 non-null   int64   \n"," 8   ticket     1000 non-null   object  \n"," 9   fare       999 non-null    float64 \n"," 10  cabin      222 non-null    object  \n"," 11  embarked   999 non-null    object  \n"," 12  home.dest  573 non-null    object  \n"," 13  Interval   1000 non-null   category\n","dtypes: category(1), float64(2), int64(5), object(6)\n","memory usage: 110.5+ KB\n"]},{"data":{"text/plain":["None"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","Index: 1000 entries, 53 to 652\n","Data columns (total 14 columns):\n"," #   Column     Non-Null Count  Dtype   \n","---  ------     --------------  -----   \n"," 0   ID         1000 non-null   int64   \n"," 1   survived   1000 non-null   int64   \n"," 2   pclass     1000 non-null   int64   \n"," 3   name       1000 non-null   object  \n"," 4   sex        1000 non-null   object  \n"," 5   age        1000 non-null   float64 \n"," 6   sibsp      1000 non-null   int64   \n"," 7   parch      1000 non-null   int64   \n"," 8   ticket     1000 non-null   object  \n"," 9   fare       999 non-null    float64 \n"," 10  cabin      222 non-null    object  \n"," 11  embarked   999 non-null    object  \n"," 12  home.dest  573 non-null    object  \n"," 13  Interval   1000 non-null   category\n","dtypes: category(1), float64(2), int64(5), object(6)\n","memory usage: 110.5+ KB\n"]},{"data":{"text/plain":["None"]},"metadata":{},"output_type":"display_data"}],"source":["df = pd.read_csv(\"data.csv\")\n","# df.info()\n","df.isnull().sum()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Convert the embarked column into 0/1/2."]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["df.embarked = df.embarked.replace({\"C\": 0, \"Q\": 1, \"S\": 2})"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Missing values in columns I plan to use are filled in with the mean of that column."]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"data":{"text/plain":["ID             0\n","survived       0\n","pclass         0\n","name           0\n","sex            0\n","age            0\n","sibsp          0\n","parch          0\n","ticket         0\n","fare           0\n","cabin        778\n","embarked       0\n","home.dest    427\n","dtype: int64"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["df.age = df.age.fillna(df.age.mean())\n","df.fare = df.fare.fillna(df.fare.mean())\n","df.embarked = df.embarked.fillna(floor(df.embarked.mean()))\n","df.isnull().sum()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["There is not enough data for cabin and home destination, so I drop it."]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["df = df.drop(columns=[\"cabin\", \"home.dest\"])"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Convert sex into 0/1."]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["df.sex = df.sex.replace({\"male\": 0, \"female\": 1})"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Checking what has what impact on surviving."]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>survived</th>\n","      <th>pclass</th>\n","      <th>sex</th>\n","      <th>age</th>\n","      <th>sibsp</th>\n","      <th>parch</th>\n","      <th>fare</th>\n","      <th>embarked</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>ID</th>\n","      <td>1.000000</td>\n","      <td>-0.030423</td>\n","      <td>0.038144</td>\n","      <td>-0.019001</td>\n","      <td>-0.019708</td>\n","      <td>0.000396</td>\n","      <td>-0.032359</td>\n","      <td>-0.022320</td>\n","      <td>0.025025</td>\n","    </tr>\n","    <tr>\n","      <th>survived</th>\n","      <td>-0.030423</td>\n","      <td>1.000000</td>\n","      <td>-0.306425</td>\n","      <td>0.533893</td>\n","      <td>-0.035877</td>\n","      <td>-0.022323</td>\n","      <td>0.086493</td>\n","      <td>0.241509</td>\n","      <td>-0.163003</td>\n","    </tr>\n","    <tr>\n","      <th>pclass</th>\n","      <td>0.038144</td>\n","      <td>-0.306425</td>\n","      <td>1.000000</td>\n","      <td>-0.121329</td>\n","      <td>-0.353733</td>\n","      <td>0.059313</td>\n","      <td>0.026576</td>\n","      <td>-0.545761</td>\n","      <td>0.178336</td>\n","    </tr>\n","    <tr>\n","      <th>sex</th>\n","      <td>-0.019001</td>\n","      <td>0.533893</td>\n","      <td>-0.121329</td>\n","      <td>1.000000</td>\n","      <td>-0.056748</td>\n","      <td>0.123758</td>\n","      <td>0.244412</td>\n","      <td>0.181520</td>\n","      <td>-0.094325</td>\n","    </tr>\n","    <tr>\n","      <th>age</th>\n","      <td>-0.019708</td>\n","      <td>-0.035877</td>\n","      <td>-0.353733</td>\n","      <td>-0.056748</td>\n","      <td>1.000000</td>\n","      <td>-0.202125</td>\n","      <td>-0.126964</td>\n","      <td>0.169821</td>\n","      <td>-0.074440</td>\n","    </tr>\n","    <tr>\n","      <th>sibsp</th>\n","      <td>0.000396</td>\n","      <td>-0.022323</td>\n","      <td>0.059313</td>\n","      <td>0.123758</td>\n","      <td>-0.202125</td>\n","      <td>1.000000</td>\n","      <td>0.370997</td>\n","      <td>0.140273</td>\n","      <td>0.066780</td>\n","    </tr>\n","    <tr>\n","      <th>parch</th>\n","      <td>-0.032359</td>\n","      <td>0.086493</td>\n","      <td>0.026576</td>\n","      <td>0.244412</td>\n","      <td>-0.126964</td>\n","      <td>0.370997</td>\n","      <td>1.000000</td>\n","      <td>0.199704</td>\n","      <td>0.062697</td>\n","    </tr>\n","    <tr>\n","      <th>fare</th>\n","      <td>-0.022320</td>\n","      <td>0.241509</td>\n","      <td>-0.545761</td>\n","      <td>0.181520</td>\n","      <td>0.169821</td>\n","      <td>0.140273</td>\n","      <td>0.199704</td>\n","      <td>1.000000</td>\n","      <td>-0.230909</td>\n","    </tr>\n","    <tr>\n","      <th>embarked</th>\n","      <td>0.025025</td>\n","      <td>-0.163003</td>\n","      <td>0.178336</td>\n","      <td>-0.094325</td>\n","      <td>-0.074440</td>\n","      <td>0.066780</td>\n","      <td>0.062697</td>\n","      <td>-0.230909</td>\n","      <td>1.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                ID  survived    pclass       sex       age     sibsp  \\\n","ID        1.000000 -0.030423  0.038144 -0.019001 -0.019708  0.000396   \n","survived -0.030423  1.000000 -0.306425  0.533893 -0.035877 -0.022323   \n","pclass    0.038144 -0.306425  1.000000 -0.121329 -0.353733  0.059313   \n","sex      -0.019001  0.533893 -0.121329  1.000000 -0.056748  0.123758   \n","age      -0.019708 -0.035877 -0.353733 -0.056748  1.000000 -0.202125   \n","sibsp     0.000396 -0.022323  0.059313  0.123758 -0.202125  1.000000   \n","parch    -0.032359  0.086493  0.026576  0.244412 -0.126964  0.370997   \n","fare     -0.022320  0.241509 -0.545761  0.181520  0.169821  0.140273   \n","embarked  0.025025 -0.163003  0.178336 -0.094325 -0.074440  0.066780   \n","\n","             parch      fare  embarked  \n","ID       -0.032359 -0.022320  0.025025  \n","survived  0.086493  0.241509 -0.163003  \n","pclass    0.026576 -0.545761  0.178336  \n","sex       0.244412  0.181520 -0.094325  \n","age      -0.126964  0.169821 -0.074440  \n","sibsp     0.370997  0.140273  0.066780  \n","parch     1.000000  0.199704  0.062697  \n","fare      0.199704  1.000000 -0.230909  \n","embarked  0.062697 -0.230909  1.000000  "]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["cor_matrix = df.corr(numeric_only=True)\n","cor_matrix"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Sibling, spouses, parents and children all have small impact, so I combined them into having **family**."]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["def family(x):\n","    return 1 if (x[\"sibsp\"] + x[\"parch\"] > 0) else 0\n","\n","df[\"family\"] = df.apply(family, axis=1)\n","df = df.drop(columns=[\"sibsp\", \"parch\"])"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["I could use titles from the name column, but it seems like too little reward for too much effort and I would need to convert it from string somehow. Same goes for the ticket."]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["df = df.drop(columns=[\"name\", \"ticket\"])"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Now I have only numeric values."]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"data":{"text/plain":["ID            int64\n","survived      int64\n","pclass        int64\n","sex           int64\n","age         float64\n","fare        float64\n","embarked    float64\n","family        int64\n","dtype: object"]},"metadata":{},"output_type":"display_data"}],"source":["display(df.dtypes)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Last look at the data."]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>survived</th>\n","      <th>pclass</th>\n","      <th>sex</th>\n","      <th>age</th>\n","      <th>fare</th>\n","      <th>embarked</th>\n","      <th>family</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>27.000000</td>\n","      <td>7.7958</td>\n","      <td>2.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>45.000000</td>\n","      <td>8.0500</td>\n","      <td>2.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>30.006692</td>\n","      <td>0.0000</td>\n","      <td>2.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>27.000000</td>\n","      <td>11.1333</td>\n","      <td>2.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>28.000000</td>\n","      <td>82.1708</td>\n","      <td>0.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>995</th>\n","      <td>995</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>22.000000</td>\n","      <td>151.5500</td>\n","      <td>2.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>996</th>\n","      <td>996</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>21.000000</td>\n","      <td>73.5000</td>\n","      <td>2.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>997</th>\n","      <td>997</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>24.000000</td>\n","      <td>69.3000</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>998</th>\n","      <td>998</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>30.006692</td>\n","      <td>69.5500</td>\n","      <td>2.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>999</th>\n","      <td>999</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>20.000000</td>\n","      <td>7.0500</td>\n","      <td>2.0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1000 rows × 8 columns</p>\n","</div>"],"text/plain":["      ID  survived  pclass  sex        age      fare  embarked  family\n","0      0         1       3    0  27.000000    7.7958       2.0       0\n","1      1         1       3    0  45.000000    8.0500       2.0       0\n","2      2         0       2    0  30.006692    0.0000       2.0       0\n","3      3         1       3    1  27.000000   11.1333       2.0       1\n","4      4         0       1    0  28.000000   82.1708       0.0       1\n","..   ...       ...     ...  ...        ...       ...       ...     ...\n","995  995         1       1    1  22.000000  151.5500       2.0       0\n","996  996         0       2    0  21.000000   73.5000       2.0       0\n","997  997         1       1    1  24.000000   69.3000       0.0       0\n","998  998         0       3    0  30.006692   69.5500       2.0       1\n","999  999         0       3    0  20.000000    7.0500       2.0       0\n","\n","[1000 rows x 8 columns]"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["df\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Separate the target variable from the rest of the data"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["ydata = df.survived\n","Xdata = df.drop(\"survived\", axis = 1)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Set random seed and split data into train, test, validattion sets."]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["rd_seed = 666\n","Xtrain, Xtest, ytrain, ytest = train_test_split(Xdata, ydata, test_size=0.5, random_state=rd_seed) "]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Train dimension, X: (500, 7), y: (500,)\n","Val dimension, X: (250, 7), y: (250,)\n","Test dimension, X: (250, 7), y: (250,)\n"]}],"source":["Xval, Xtest, yval, ytest = train_test_split(Xtest, ytest, test_size=0.5, random_state=rd_seed) \n","print(f\"Train dimension, X: {Xtrain.shape}, y: {ytrain.shape}\")\n","print(f\"Val dimension, X: {Xval.shape}, y: {yval.shape}\")\n","print(f\"Test dimension, X: {Xtest.shape}, y: {ytest.shape}\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Parameter grid for all possible combinations."]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["param_grid = {\n","    'max_depth': range(1,42), \n","    'criterion': ['entropy', 'gini', 'log_loss']\n","}\n","param_comb = ParameterGrid(param_grid)\n","val_acc = []"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Loop through the combinations and find the best one."]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["for params in param_comb:\n","    dt = DecisionTreeClassifier(max_depth=params['max_depth'], criterion=params['criterion'])\n","    dt.fit(Xtrain, ytrain)\n","    val_acc.append(metrics.accuracy_score(yval, dt.predict(Xval)))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Print out the best parameters and accuracy score for those parameters."]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["best params {'max_depth': 3, 'criterion': 'entropy'}\n","accuracy score (train): 0.8320\n","accuracy score (validation): 0.7800\n","accuracy score (test): 0.8040\n"]}],"source":["best_params = param_comb[np.argmax(val_acc)]\n","print(f'best params {best_params}')\n","\n","dt = DecisionTreeClassifier(max_depth=best_params['max_depth'], criterion=best_params['criterion'])\n","dt.fit(Xtrain, ytrain)\n","\n","print(f'accuracy score (train): {dt.score(Xtrain, ytrain):0.4f}')\n","print(f'accuracy score (validation): {dt.score(Xval, yval):0.4f}')\n","print(f'accuracy score (test): {metrics.accuracy_score(ytest, dt.predict(Xtest)):0.4f}')"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["I tried the same for KNN, but the results were worse."]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Best number of neighbors 4\n","accuracy score (train): 0.7360\n","accuracy score (validation): 0.5720\n","accuracy score (test): 0.6040\n"]}],"source":["val_acc = []\n","\n","kneighbors = range(3,15)\n","for k in kneighbors:\n","    clf = KNeighborsClassifier(n_neighbors = k)\n","    clf.fit(Xtrain, ytrain)\n","    val_acc.append(clf.score(Xval, yval))\n","\n","best_k = np.argmax(val_acc)\n","\n","clf = KNeighborsClassifier(n_neighbors = best_k)\n","clf.fit(Xtrain, ytrain)\n","\n","print(f'Best number of neighbors {best_k}')\n","print(f'accuracy score (train): {clf.score(Xtrain, ytrain):0.4f}')\n","print(f'accuracy score (validation): {clf.score(Xval, yval):0.4f}')\n","print(f'accuracy score (test): {metrics.accuracy_score(ytest, clf.predict(Xtest)):0.4f}')"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["So I tried to scale the data."]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["scaler = MinMaxScaler()\n","Xtrain_scaled = scaler.fit_transform(Xtrain)\n","Xval_scaled = scaler.transform(Xval)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["It's better, but still worse."]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Best number of neighbors 4\n","accuracy score (train): 0.8440\n","accuracy score (validation): 0.7400\n","accuracy score (test): 0.6760\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Brumda\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n","  warnings.warn(\n"]}],"source":["val_acc = []\n","kneighbors = range(3,15)\n","\n","for k in kneighbors:\n","    clf = KNeighborsClassifier(n_neighbors = k)\n","    clf.fit(Xtrain_scaled, ytrain)\n","    val_acc.append(clf.score(Xval_scaled, yval))\n","\n","best_k = np.argmax(val_acc)\n","\n","clf = KNeighborsClassifier(n_neighbors = best_k)\n","clf.fit(Xtrain_scaled, ytrain)\n","\n","print(f'Best number of neighbors {best_k}')\n","print(f'accuracy score (train): {clf.score(Xtrain_scaled, ytrain):0.4f}')\n","print(f'accuracy score (validation): {clf.score(Xval_scaled, yval):0.4f}')\n","print(f'accuracy score (test): {metrics.accuracy_score(ytest, clf.predict(Xtest)):0.4f}')"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["With my model, the decision tree is not really good, but still better than the KNN."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Load the evaluation data and prepare them the same way as the original ones."]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"data":{"text/plain":["ID          0\n","pclass      0\n","sex         0\n","age         0\n","fare        0\n","embarked    0\n","family      0\n","dtype: int64"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["eval = pd.read_csv(\"evaluation.csv\")\n","\n","eval.embarked = eval.embarked.replace({\"C\": 0, \"Q\": 1, \"S\": 2})\n","eval.age = eval.age.fillna(eval.age.mean())\n","eval.fare = eval.fare.fillna(eval.fare.mean())\n","eval.embarked = eval.embarked.fillna(floor(eval.embarked.mean()))\n","eval = eval.drop(columns=[\"cabin\", \"home.dest\"])\n","eval.sex = eval.sex.replace({\"male\": 0, \"female\": 1})\n","def family(x):\n","    return 1 if (x[\"sibsp\"] + x[\"parch\"] > 0) else 0\n","\n","eval[\"family\"] = eval.apply(family, axis=1)\n","eval = eval.drop(columns=[\"sibsp\", \"parch\"])\n","eval = eval.drop(columns=[\"name\", \"ticket\"])\n","eval.isnull().sum()\n","# eval"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Trained decision tree is predicting the survive value for new data."]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(309,)\n"]}],"source":["prediction = dt.predict(eval)\n","print(prediction.shape)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Putting everything into result.csv file."]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["ID = eval['ID']\n","test_Survived = pd.Series(dt.predict(eval), name=\"Survived\")\n","\n","results = pd.concat([ID, test_Survived], axis=1)\n","\n","results.to_csv(\"result.csv\", index=False)"]}],"metadata":{"deepnote":{},"deepnote_execution_queue":[],"deepnote_notebook_id":"c3253498bf634c08b4d8ba7123b0b9b9","kernelspec":{"display_name":"Python 3.10.8 64-bit (microsoft store)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.2"},"orig_nbformat":2,"vscode":{"interpreter":{"hash":"ef2fc1de8e2dcbb06a92b5998de390c246026ddc4c36cbda52e3ec732ce1a64d"}}},"nbformat":4,"nbformat_minor":0}
